{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from time import gmtime, strftime\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    from moviepy.editor import VideoFileClip\n",
    "except:\n",
    "    # If FFmpeg (https://www.ffmpeg.org/) is not found on the computer,\n",
    "    # it will be downloaded from Internet (an Internet connect is needed)\n",
    "    import imageio\n",
    "    imageio.plugins.ffmpeg.download()\n",
    "    from moviepy.editor import VideoFileClip\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "class DetectionObj(object):\n",
    "    \"\"\"\n",
    "    DetectionObj is a class suitable to leverage Google Tensorflow\n",
    "    detection API for image annotation from different sources:\n",
    "    files, images acquired by own's webcam, videos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model='ssd_mobilenet_v1_coco_11_06_2017'):\n",
    "        \"\"\"\n",
    "        The instructions to be run when the class is instantiated\n",
    "        \"\"\"\n",
    "\n",
    "        # Path where the Python script is being run\n",
    "        self.CURRENT_PATH = os.getcwd()\n",
    "\n",
    "        # Path where to save the annotations (it can be modified)\n",
    "        self.TARGET_PATH = self.CURRENT_PATH\n",
    "\n",
    "        # Selection of pre-trained detection models\n",
    "        # from the Tensorflow Model Zoo\n",
    "        self.MODELS = [\"ssd_mobilenet_v1_coco_11_06_2017\",\n",
    "                       \"ssd_inception_v2_coco_11_06_2017\",\n",
    "                       \"rfcn_resnet101_coco_11_06_2017\",\n",
    "                       \"faster_rcnn_resnet101_coco_11_06_2017\",\n",
    "                       \"faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017\"\n",
    "                       ]\n",
    "\n",
    "        # Setting a threshold for detecting an object by the models\n",
    "        self.THRESHOLD = 0.25 # Most used threshold in practice\n",
    "\n",
    "        # Checking if the desired pre-trained detection model is available\n",
    "        if model in self.MODELS:\n",
    "            self.MODEL_NAME = model\n",
    "        else:\n",
    "            # Otherwise revert to a default model\n",
    "            print(\"Model not available, reverted to default\", self.MODELS[0])\n",
    "            self.MODEL_NAME = self.MODELS[0]\n",
    "\n",
    "        # The file name of the Tensorflow frozen model\n",
    "        self.CKPT_FILE = os.path.join(self.CURRENT_PATH, 'object_detection',\n",
    "                                      self.MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "\n",
    "        # Attempting loading the detection model, if not available on disk,\n",
    "        # it will be downloaded from Internet(an Internet connection is required)\n",
    "        try:\n",
    "            self.DETECTION_GRAPH = self.load_frozen_model()\n",
    "        except:\n",
    "            print ('Couldn\\'t find', self.MODEL_NAME)\n",
    "            self.download_frozen_model()\n",
    "            self.DETECTION_GRAPH = self.load_frozen_model()\n",
    "\n",
    "        # Loading the labels of the classes recognized by the detection model\n",
    "        self.NUM_CLASSES = 90\n",
    "        path_to_labels = os.path.join(self.CURRENT_PATH,\n",
    "                                      'object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "        label_mapping = label_map_util.load_labelmap(path_to_labels)\n",
    "        extracted_categories = label_map_util.convert_label_map_to_categories(label_mapping,\n",
    "                                                                    max_num_classes=self.NUM_CLASSES,\n",
    "                                                                    use_display_name=True)\n",
    "        self.LABELS = {item['id']: item['name'] for item in extracted_categories}\n",
    "        self.CATEGORY_INDEX = label_map_util.create_category_index(extracted_categories)\n",
    "\n",
    "        # Starting the tensorflow session\n",
    "        self.TF_SESSION = tf.Session(graph=self.DETECTION_GRAPH)\n",
    "\n",
    "    def load_frozen_model(self):\n",
    "        \"\"\"\n",
    "        Loading frozen detection model in ckpt file from disk to memory \n",
    "        \"\"\"\n",
    "        detection_graph = tf.Graph()\n",
    "        with detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(self.CKPT_FILE, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "        return detection_graph\n",
    "\n",
    "    def download_frozen_model(self):\n",
    "        \"\"\"\n",
    "        Downloading frozen detection model from Internet \n",
    "        when not available on disk \n",
    "        \"\"\"\n",
    "        def my_hook(t):\n",
    "            \"\"\"\n",
    "            Wrapping tqdm instance in order to monitor URLopener  \n",
    "            \"\"\"\n",
    "            last_b = [0]\n",
    "\n",
    "            def inner(b=1, bsize=1, tsize=None):\n",
    "                if tsize is not None:\n",
    "                    t.total = tsize\n",
    "                t.update((b - last_b[0]) * bsize)\n",
    "                last_b[0] = b\n",
    "\n",
    "            return inner\n",
    "\n",
    "        # Opening the url where to find the model\n",
    "        model_filename = self.MODEL_NAME + '.tar.gz'\n",
    "        download_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "        opener = urllib.request.URLopener()\n",
    "\n",
    "        # Downloading the model with tqdm estimations of completion\n",
    "        print('Downloading ...')\n",
    "        with tqdm() as t:\n",
    "            opener.retrieve(download_url + model_filename,\n",
    "                            model_filename, reporthook=my_hook(t))\n",
    "\n",
    "        # Extracting the model from the downloaded tar file\n",
    "        print ('Extracting ...')\n",
    "        tar_file = tarfile.open(model_filename)\n",
    "        for file in tar_file.getmembers():\n",
    "            file_name = os.path.basename(file.name)\n",
    "            if 'frozen_inference_graph.pb' in file_name:\n",
    "                tar_file.extract(file, os.path.join(self.CURRENT_PATH,\n",
    "                                                    'object_detection'))\n",
    "\n",
    "    def load_image_from_disk(self, image_path):\n",
    "        \"\"\"\n",
    "        Loading an image from disk\n",
    "        \"\"\"\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    def load_image_into_numpy_array(self, image):\n",
    "        \"\"\"\n",
    "        Turning an image into a Numpy ndarray\n",
    "        \"\"\"\n",
    "        try:\n",
    "            (im_width, im_height) = image.size\n",
    "            return np.array(image.getdata()).reshape(\n",
    "                (im_height, im_width, 3)).astype(np.uint8)\n",
    "        except:\n",
    "            # If the previous procedure fails, we expect the\n",
    "            # image is already a Numpy ndarray\n",
    "            return image\n",
    "\n",
    "    def detect(self, images, annotate_on_image=True):\n",
    "        \"\"\"\n",
    "        Processing a list of images, feeding it into the detection\n",
    "        model and getting from it scores, bounding boxes and predicted\n",
    "        classes present in the images\n",
    "        \"\"\"\n",
    "        if type(images) is not list:\n",
    "            images = [images]\n",
    "        results = list()\n",
    "        for image in images:\n",
    "            # the array based representation of the image will be used later in order to prepare the resulting\n",
    "            # image with boxes and labels on it.\n",
    "            image_np = self.load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = self.DETECTION_GRAPH.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = self.DETECTION_GRAPH.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score could be shown on the result image, together with the class label.\n",
    "            scores = self.DETECTION_GRAPH.get_tensor_by_name('detection_scores:0')\n",
    "            classes = self.DETECTION_GRAPH.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = self.DETECTION_GRAPH.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection happens here\n",
    "            (boxes, scores, classes, num_detections) = self.TF_SESSION.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            if annotate_on_image:\n",
    "                new_image = self.detection_on_image(image_np, boxes, scores, classes)\n",
    "                results.append((new_image, boxes, scores, classes, num_detections))\n",
    "            else:\n",
    "                results.append((image_np, boxes, scores, classes, num_detections))\n",
    "        return results\n",
    "\n",
    "    def detection_on_image(self, image_np, boxes, scores, classes):\n",
    "        \"\"\"\n",
    "        Overimposing detection boxes on the images over the detected classes: \n",
    "        \"\"\"\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            self.CATEGORY_INDEX,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8)\n",
    "        return image_np\n",
    "\n",
    "    def visualize_image(self, image_np, image_size=(400, 300), latency=3, bluish_correction=True):\n",
    "        \"\"\"\n",
    "        Visualizing an image\n",
    "        \"\"\"\n",
    "        height, width, depth = image_np.shape\n",
    "        reshaper = height / float(image_size[0])\n",
    "        width = int(width / reshaper)\n",
    "        height = int(height / reshaper)\n",
    "        id_img = 'preview_' + str(np.sum(image_np))\n",
    "        cv2.startWindowThread()\n",
    "        cv2.namedWindow(id_img, cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(id_img, width, height)\n",
    "        if bluish_correction:\n",
    "            RGB_img = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imshow(id_img, RGB_img)\n",
    "        else:\n",
    "            cv2.imshow(id_img, image_np)\n",
    "        cv2.waitKey(latency*1000)\n",
    "\n",
    "    def serialize_annotations(self, boxes, scores, classes, filename='data.json'):\n",
    "        \"\"\"\n",
    "        Saving annotations to disk, on a JSON file\n",
    "        \"\"\"\n",
    "        threshold = self.THRESHOLD\n",
    "        valid = [position for position, score in enumerate(scores[0]) if score > threshold]\n",
    "        if len(valid) > 0:\n",
    "            valid_scores = scores[0][valid].tolist()\n",
    "            valid_boxes  = boxes[0][valid].tolist()\n",
    "            valid_class = [self.LABELS[int(a_class)] for a_class in classes[0][valid]]\n",
    "            with open(filename, 'w') as outfile:\n",
    "                json_data = json.dumps({'classes': valid_class,\n",
    "                                        'boxes':valid_boxes, 'scores': valid_scores})\n",
    "                json.dump(json_data, outfile)\n",
    "\n",
    "    def get_time(self):\n",
    "        \"\"\"\n",
    "        Returning a string reporting the actual date and time\n",
    "        \"\"\"\n",
    "        return strftime(\"%Y-%m-%d_%Hh%Mm%Ss\", gmtime())\n",
    "\n",
    "    def annotate_photogram(self, photogram):\n",
    "        \"\"\"\n",
    "        Annotating a video's photogram with bounding boxes\n",
    "        over detected classes\n",
    "        \"\"\"\n",
    "        new_photogram, boxes, scores, classes, num_detections = self.detect(photogram)[0]\n",
    "        return new_photogram\n",
    "\n",
    "    def capture_webcam(self):\n",
    "        \"\"\"\n",
    "        Capturing an image from the integrated Webcam\n",
    "        \"\"\"\n",
    "        def get_image(device):\n",
    "            \"\"\"\n",
    "            Function to capture a single image from the camera and return it in PIL format\n",
    "            \"\"\"\n",
    "            retval, im = device.read()\n",
    "            return im\n",
    "\n",
    "        # Setting the integrated webcam\n",
    "        camera_port = 0\n",
    "\n",
    "        # Number of frames to discard as the camera adjusts to surrounding lights\n",
    "        ramp_frames = 30\n",
    "\n",
    "        # Initializing the webcam by cv2.VideoCapture.\n",
    "        camera = cv2.VideoCapture(camera_port)\n",
    "\n",
    "        # Ramping the camera - all these frames will be discarded as the camera\n",
    "        # adjusts to the light levels\n",
    "        print(\"Setting the webcam\")\n",
    "        for i in range(ramp_frames):\n",
    "            _ = get_image(camera)\n",
    "\n",
    "        # Taking the snapshot\n",
    "        print(\"Now taking a snapshot ... \", end='')\n",
    "        camera_capture = get_image(camera)\n",
    "        print('Done')\n",
    "\n",
    "        # releasing the camera and making it reusable\n",
    "        del (camera)\n",
    "        return camera_capture\n",
    "\n",
    "    def file_pipeline(self, images, visualize=True):\n",
    "        \"\"\"\n",
    "        A pipeline for processing and annotating lists of\n",
    "        images to load from disk\n",
    "        \"\"\"\n",
    "        if type(images) is not list:\n",
    "            images = [images]\n",
    "        for filename in images:\n",
    "            single_image = self.load_image_from_disk(filename)\n",
    "            for new_image, boxes, scores, classes, num_detections in self.detect(single_image):\n",
    "                self.serialize_annotations(boxes, scores, classes,\n",
    "                                           filename=filename + \".json\")\n",
    "                if visualize:\n",
    "                    self.visualize_image(new_image)\n",
    "\n",
    "    def video_pipeline(self, video, audio=False):\n",
    "        \"\"\"\n",
    "        A pipeline to process a video on disk and annotating it\n",
    "        by bounding box. The output is a new annotated video.\n",
    "        \"\"\"\n",
    "        clip = VideoFileClip(video)\n",
    "        new_video = video.split('/')\n",
    "        new_video[-1] = \"annotated_\" + new_video[-1]\n",
    "        new_video = '/'.join(new_video)\n",
    "        print(\"Saving annotated video to\", new_video)\n",
    "        video_annotation = clip.fl_image(self.annotate_photogram)\n",
    "        video_annotation.write_videofile(new_video, audio=audio)\n",
    "\n",
    "    def webcam_pipeline(self):\n",
    "        \"\"\"\n",
    "        A pipeline to process an image acquired by the internal webcam\n",
    "        and annotate it, saving a JSON file to disk\n",
    "        \"\"\"\n",
    "        webcam_image = self.capture_webcam()\n",
    "        filename = \"webcam_\" + self.get_time()\n",
    "        saving_path = os.path.join(self.CURRENT_PATH, filename + \".jpg\")\n",
    "        cv2.imwrite(saving_path, webcam_image)\n",
    "        new_image, boxes, scores, classes, num_detections = self.detect(webcam_image)[0]\n",
    "        json_obj = {'classes': classes, 'boxes':boxes, 'scores':scores}\n",
    "        self.serialize_annotations(boxes, scores, classes,\n",
    "                                   filename=filename+\".json\")\n",
    "        self.visualize_image(new_image, bluish_correction=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
