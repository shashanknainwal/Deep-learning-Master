{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Pricing- Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.2,  42.3,  50. ,  21.1,  17.7,  18.5,  11.3,  15.6,  15.6,\n",
       "        14.4,  12.1,  17.9,  23.1,  19.9,  15.7,   8.8,  50. ,  22.5,\n",
       "        24.1,  27.5,  10.9,  30.8,  32.9,  24. ,  18.5,  13.3,  22.9,\n",
       "        34.7,  16.6,  17.5,  22.3,  16.1,  14.9,  23.1,  34.9,  25. ,\n",
       "        13.9,  13.1,  20.4,  20. ,  15.2,  24.7,  22.2,  16.7,  12.7,\n",
       "        15.6,  18.4,  21. ,  30.1,  15.1,  18.7,   9.6,  31.5,  24.8,\n",
       "        19.1,  22. ,  14.5,  11. ,  32. ,  29.4,  20.3,  24.4,  14.6,\n",
       "        19.5,  14.1,  14.3,  15.6,  10.5,   6.3,  19.3,  19.3,  13.4,\n",
       "        36.4,  17.8,  13.5,  16.5,   8.3,  14.3,  16. ,  13.4,  28.6,\n",
       "        43.5,  20.2,  22. ,  23. ,  20.7,  12.5,  48.5,  14.6,  13.4,\n",
       "        23.7,  50. ,  21.7,  39.8,  38.7,  22.2,  34.9,  22.5,  31.1,\n",
       "        28.7,  46. ,  41.7,  21. ,  26.6,  15. ,  24.4,  13.3,  21.2,\n",
       "        11.7,  21.7,  19.4,  50. ,  22.8,  19.7,  24.7,  36.2,  14.2,\n",
       "        18.9,  18.3,  20.6,  24.6,  18.2,   8.7,  44. ,  10.4,  13.2,\n",
       "        21.2,  37. ,  30.7,  22.9,  20. ,  19.3,  31.7,  32. ,  23.1,\n",
       "        18.8,  10.9,  50. ,  19.6,   5. ,  14.4,  19.8,  13.8,  19.6,\n",
       "        23.9,  24.5,  25. ,  19.9,  17.2,  24.6,  13.5,  26.6,  21.4,\n",
       "        11.9,  22.6,  19.6,   8.5,  23.7,  23.1,  22.4,  20.5,  23.6,\n",
       "        18.4,  35.2,  23.1,  27.9,  20.6,  23.7,  28. ,  13.6,  27.1,\n",
       "        23.6,  20.6,  18.2,  21.7,  17.1,   8.4,  25.3,  13.8,  22.2,\n",
       "        18.4,  20.7,  31.6,  30.5,  20.3,   8.8,  19.2,  19.4,  23.1,\n",
       "        23. ,  14.8,  48.8,  22.6,  33.4,  21.1,  13.6,  32.2,  13.1,\n",
       "        23.4,  18.9,  23.9,  11.8,  23.3,  22.8,  19.6,  16.7,  13.4,\n",
       "        22.2,  20.4,  21.8,  26.4,  14.9,  24.1,  23.8,  12.3,  29.1,\n",
       "        21. ,  19.5,  23.3,  23.8,  17.8,  11.5,  21.7,  19.9,  25. ,\n",
       "        33.4,  28.5,  21.4,  24.3,  27.5,  33.1,  16.2,  23.3,  48.3,\n",
       "        22.9,  22.8,  13.1,  12.7,  22.6,  15. ,  15.3,  10.5,  24. ,\n",
       "        18.5,  21.7,  19.5,  33.2,  23.2,   5. ,  19.1,  12.7,  22.3,\n",
       "        10.2,  13.9,  16.3,  17. ,  20.1,  29.9,  17.2,  37.3,  45.4,\n",
       "        17.8,  23.2,  29. ,  22. ,  18. ,  17.4,  34.6,  20.1,  25. ,\n",
       "        15.6,  24.8,  28.2,  21.2,  21.4,  23.8,  31. ,  26.2,  17.4,\n",
       "        37.9,  17.5,  20. ,   8.3,  23.9,   8.4,  13.8,   7.2,  11.7,\n",
       "        17.1,  21.6,  50. ,  16.1,  20.4,  20.6,  21.4,  20.6,  36.5,\n",
       "         8.5,  24.8,  10.8,  21.9,  17.3,  18.9,  36.2,  14.9,  18.2,\n",
       "        33.3,  21.8,  19.7,  31.6,  24.8,  19.4,  22.8,   7.5,  44.8,\n",
       "        16.8,  18.7,  50. ,  50. ,  19.5,  20.1,  50. ,  17.2,  20.8,\n",
       "        19.3,  41.3,  20.4,  20.5,  13.8,  16.5,  23.9,  20.6,  31.5,\n",
       "        23.3,  16.8,  14. ,  33.8,  36.1,  12.8,  18.3,  18.7,  19.1,\n",
       "        29. ,  30.1,  50. ,  50. ,  22. ,  11.9,  37.6,  50. ,  22.7,\n",
       "        20.8,  23.5,  27.9,  50. ,  19.3,  23.9,  22.6,  15.2,  21.7,\n",
       "        19.2,  43.8,  20.3,  33.2,  19.9,  22.5,  32.7,  22. ,  17.1,\n",
       "        19. ,  15. ,  16.1,  25.1,  23.7,  28.7,  37.2,  22.6,  16.4,\n",
       "        25. ,  29.8,  22.1,  17.4,  18.1,  30.3,  17.5,  24.7,  12.6,\n",
       "        26.5,  28.7,  13.3,  10.4,  24.4,  23. ,  20. ,  17.8,   7. ,\n",
       "        11.8,  24.4,  13.8,  19.4,  25.2,  19.4,  19.4,  29.1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "# median housing pricing in thousands of dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The idea behind StandardScaler is that it will transform your data such that its distribution will have a mean value 0 and standard deviation of 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Method 1- Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sc_X.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = sc_X.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ..., \n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create base model\n",
    "def base_model():\n",
    "    model= models.Sequential()\n",
    "    model.add(layers.Dense(64,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mse',metrics=['MAE'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cross hold out validation set using K -fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 269.90%\n",
      "269.90% (+/- 0.00%)\n",
      "mean_absolute_error: 256.51%\n",
      "263.21% (+/- 6.69%)\n",
      "mean_absolute_error: 251.19%\n",
      "259.20% (+/- 7.87%)\n",
      "mean_absolute_error: 284.84%\n",
      "265.61% (+/- 13.03%)\n",
      "mean_absolute_error: 263.38%\n",
      "265.17% (+/- 11.69%)\n",
      "mean_absolute_error: 254.89%\n",
      "263.45% (+/- 11.33%)\n",
      "mean_absolute_error: 260.33%\n",
      "263.01% (+/- 10.55%)\n",
      "mean_absolute_error: 261.33%\n",
      "262.80% (+/- 9.88%)\n",
      "mean_absolute_error: 299.22%\n",
      "266.84% (+/- 14.76%)\n",
      "mean_absolute_error: 247.96%\n",
      "264.96% (+/- 15.11%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=101)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model= models.Sequential()\n",
    "    model.add(layers.Dense(64,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mse',metrics=['MAE'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "    model.fit(x_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264.95617847816618"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[269.90453589196301,\n",
       " 256.51495035956884,\n",
       " 251.19181240306182,\n",
       " 284.83675414440677,\n",
       " 263.38058826970121,\n",
       " 254.88658792832317,\n",
       " 260.33456933264637,\n",
       " 261.32997344521914,\n",
       " 299.22044136944936,\n",
       " 247.96157163732192]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4\n",
    "no_of_val_sample= len(x_train)//k\n",
    "all_scores=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(k):\n",
    "    val_data= x_train[i*no_of_val_sample:(i+1)*no_of_val_sample]\n",
    "    val_target= y_train[i*no_of_val_sample:(i+1)*no_of_val_sample]\n",
    "    partial_x_train= np.concatenate([x_train[:i*no_of_val_sample],x_train[(i+1)*no_of_val_sample:]],axis=0)\n",
    "    partial_y_train= np.concatenate([y_train[:i*no_of_val_sample],y_train[(i+1)*no_of_val_sample:]],axis=0)\n",
    "    model=base_model()\n",
    "    model.fit(partial_x_train, partial_y_train, epochs=150, batch_size=1, verbose=0)\n",
    "    val_mse,val_mae = model.evaluate(val_data, val_target, verbose=0)\n",
    "    all_scores.append(val_mae)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.mean(scores)\n",
    "av. score are 6.7K off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2- k Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(x_train) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [x_train[:i * num_val_samples],\n",
    "         x_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y_train[:i * num_val_samples],\n",
    "         y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = base_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history=model.fit(partial_train_data, partial_train_targets,validation_data=(val_data,val_targets),\n",
    "              epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    mae_history= history.history['val_mean_absolute_error']\n",
    "    # Evaluate the model on the validation data\n",
    "    #val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.959186629493638,\n",
       "  3.3860895326822109,\n",
       "  3.1058683017692945,\n",
       "  2.7067759863220817,\n",
       "  2.590225059207123,\n",
       "  2.4574509988916984,\n",
       "  2.3679593718878111,\n",
       "  2.1887245225434255,\n",
       "  2.1211296213735449,\n",
       "  2.1673299298428073,\n",
       "  2.1239849033922251,\n",
       "  2.1253555411159404,\n",
       "  2.3093184008456693,\n",
       "  1.9571776437287283,\n",
       "  2.2223888529409277,\n",
       "  2.0089330578794575,\n",
       "  2.0380139209256312,\n",
       "  2.2335999554926804,\n",
       "  2.0176251430322627,\n",
       "  2.0132907924085561,\n",
       "  2.0838207207103765,\n",
       "  1.8725645612962176,\n",
       "  2.0483651774944645,\n",
       "  1.8930102716578114,\n",
       "  1.8394144265958579,\n",
       "  1.9298315614756971,\n",
       "  2.2952087893344388,\n",
       "  2.1353651651061409,\n",
       "  1.8023029270738657,\n",
       "  1.9656358284525353,\n",
       "  2.013659184521968,\n",
       "  1.8277322561434,\n",
       "  2.5605915371734316,\n",
       "  1.9121542543467909,\n",
       "  2.0010936661521987,\n",
       "  1.9408891791164284,\n",
       "  1.8253989880627925,\n",
       "  2.4064844528047167,\n",
       "  2.7573296575262995,\n",
       "  1.9101496309337049,\n",
       "  2.0729767544434803,\n",
       "  2.396961032754124,\n",
       "  2.160227057957413,\n",
       "  1.7980018653491936,\n",
       "  2.136800784875851,\n",
       "  2.0807625326779808,\n",
       "  2.0628477228750097,\n",
       "  1.9055138767355739,\n",
       "  2.0067423924361125,\n",
       "  2.1196775247554966,\n",
       "  1.9065409367627437,\n",
       "  1.9757129555881614,\n",
       "  2.005638339731953,\n",
       "  2.1572166197370777,\n",
       "  1.9833928759735409,\n",
       "  2.3442271629182421,\n",
       "  1.9518951755939145,\n",
       "  1.9450931265802667,\n",
       "  2.1717687644580805,\n",
       "  2.1083227667478051,\n",
       "  2.4354098763796364,\n",
       "  2.0963697055778883,\n",
       "  1.8382942369668791,\n",
       "  2.4225967048418404,\n",
       "  1.9563215935584342,\n",
       "  1.9406679502808222,\n",
       "  2.045194172623134,\n",
       "  2.0991964198575159,\n",
       "  1.9469608882866283,\n",
       "  1.9938787044865069,\n",
       "  2.036880375135063,\n",
       "  2.5448316489115799,\n",
       "  2.1456419973090144,\n",
       "  2.3068043076165834,\n",
       "  2.0518601955753741,\n",
       "  2.055162722521489,\n",
       "  1.9953436709866665,\n",
       "  2.0108624307235869,\n",
       "  1.9093110112860652,\n",
       "  2.3649518985559443,\n",
       "  1.9998700500714897,\n",
       "  3.008946465973807,\n",
       "  2.076990269198276,\n",
       "  2.1907973714394147,\n",
       "  2.2662670116613408,\n",
       "  2.1339072897882745,\n",
       "  2.1787615436138492,\n",
       "  2.0238616678974415,\n",
       "  2.1017495004257354,\n",
       "  2.0993520056847297,\n",
       "  2.8113924158681738,\n",
       "  2.4377300243566533,\n",
       "  2.1076863874303231,\n",
       "  2.3541122993620314,\n",
       "  2.4143269321706033,\n",
       "  2.3450312425594517,\n",
       "  2.1120293966614372,\n",
       "  2.1221609162812185,\n",
       "  1.9777280458129278,\n",
       "  2.2308231958068245],\n",
       " [3.742222578218668,\n",
       "  2.9040563791105063,\n",
       "  3.0582002602001226,\n",
       "  2.903299865156117,\n",
       "  2.8655579821898205,\n",
       "  2.7775468165331549,\n",
       "  2.6218676142173236,\n",
       "  2.7385199990603004,\n",
       "  2.7160180535646949,\n",
       "  2.667330335862566,\n",
       "  2.7984856190067706,\n",
       "  2.8447149295618037,\n",
       "  2.5797199825249097,\n",
       "  2.6474778298104162,\n",
       "  2.6592949782267654,\n",
       "  2.610355499947425,\n",
       "  2.554068140464254,\n",
       "  2.6018090295319509,\n",
       "  2.5179337888660998,\n",
       "  2.4523839761715123,\n",
       "  2.5423422473492008,\n",
       "  2.380287736949354,\n",
       "  2.5130860923540475,\n",
       "  2.8012204500708249,\n",
       "  2.4162478494172048,\n",
       "  2.4050719289496394,\n",
       "  2.4568300719308382,\n",
       "  2.7506988449852066,\n",
       "  2.5929249631296289,\n",
       "  2.5641951891455319,\n",
       "  2.4593827181523391,\n",
       "  2.567837960649245,\n",
       "  2.484779485381476,\n",
       "  2.2991373326518749,\n",
       "  2.4253204459010966,\n",
       "  2.383062778132977,\n",
       "  2.3615116459308285,\n",
       "  2.2836485947712815,\n",
       "  2.6143835511538063,\n",
       "  2.302521327934643,\n",
       "  2.6463201069595792,\n",
       "  2.2733159678997379,\n",
       "  2.3463251331064963,\n",
       "  2.6193183861156499,\n",
       "  2.5384364694651991,\n",
       "  2.5131956799195545,\n",
       "  2.2917582398594014,\n",
       "  2.4298998719394795,\n",
       "  2.3111511504296027,\n",
       "  2.4074487686157227,\n",
       "  2.4480684865819344,\n",
       "  2.7833570584212199,\n",
       "  2.3061520510380813,\n",
       "  2.5690894835066089,\n",
       "  2.7616926419852983,\n",
       "  2.6171709334496223,\n",
       "  2.408965601779447,\n",
       "  2.7726370792577764,\n",
       "  2.357262408379281,\n",
       "  2.3405227566709614,\n",
       "  2.197213111537518,\n",
       "  2.6359307553508495,\n",
       "  2.2907778909890957,\n",
       "  2.3901631194766204,\n",
       "  2.2884161731984354,\n",
       "  2.5959038262320036,\n",
       "  2.4824900155020231,\n",
       "  2.414785847805514,\n",
       "  2.4120691743227516,\n",
       "  2.4934235846642219,\n",
       "  2.8411605853845576,\n",
       "  2.6190726780655362,\n",
       "  3.0675673626437048,\n",
       "  2.1950533932978562,\n",
       "  2.277557349441075,\n",
       "  2.6673434606873161,\n",
       "  2.9235182847126877,\n",
       "  2.6423069038013423,\n",
       "  2.5591174682768263,\n",
       "  2.3558589066609299,\n",
       "  2.6313528636894605,\n",
       "  2.4549214297001907,\n",
       "  2.5999443413007377,\n",
       "  2.7295523728474533,\n",
       "  2.4388177607319141,\n",
       "  2.5215820321942322,\n",
       "  2.7819979167220614,\n",
       "  2.436903217051289,\n",
       "  2.2873561500322701,\n",
       "  2.8289712395998512,\n",
       "  2.8606833042484698,\n",
       "  2.6919299399498664,\n",
       "  2.6162674497849872,\n",
       "  2.9546486788456985,\n",
       "  2.9317078826451066,\n",
       "  2.787404730768487,\n",
       "  2.4509396269769952,\n",
       "  2.7608838600687462,\n",
       "  2.7886033577494103,\n",
       "  2.9130725955018901],\n",
       " [4.1187835636705454,\n",
       "  3.2668006538164498,\n",
       "  2.8920525843554206,\n",
       "  2.6414339282725119,\n",
       "  3.3522049837773391,\n",
       "  2.5279473503037253,\n",
       "  2.4719498039472221,\n",
       "  2.5016727541932964,\n",
       "  2.527089836573837,\n",
       "  2.5123947658161128,\n",
       "  2.5504144465569221,\n",
       "  2.5130547509335055,\n",
       "  2.5796514902964676,\n",
       "  2.6250536748678379,\n",
       "  2.4841396407325669,\n",
       "  2.5397232263395102,\n",
       "  2.6014164981275503,\n",
       "  2.5017666675076624,\n",
       "  2.439261474231682,\n",
       "  2.44658622647276,\n",
       "  2.7025864856077892,\n",
       "  2.5421671395254606,\n",
       "  2.3976214758240348,\n",
       "  2.4476638123540595,\n",
       "  2.451144553647183,\n",
       "  2.5430532918118014,\n",
       "  2.4678074392941918,\n",
       "  2.4072893539277636,\n",
       "  2.3659054170740714,\n",
       "  2.3143644474520544,\n",
       "  2.4289568249541933,\n",
       "  2.3113662039879523,\n",
       "  2.4499621296873189,\n",
       "  2.4160453210962882,\n",
       "  2.6559256704727021,\n",
       "  2.4758353941511402,\n",
       "  2.641456197984148,\n",
       "  2.776579167583201,\n",
       "  2.511967361563503,\n",
       "  2.5478607262715256,\n",
       "  2.380482768068219,\n",
       "  2.4014689237764566,\n",
       "  2.4439573004694268,\n",
       "  2.4092256574347468,\n",
       "  2.7099960534879477,\n",
       "  2.3907321703315962,\n",
       "  2.5713848642783588,\n",
       "  2.674336872478523,\n",
       "  2.9496042421548672,\n",
       "  2.4602838459581431,\n",
       "  2.5221267407483392,\n",
       "  2.7147922704715541,\n",
       "  2.561139767712886,\n",
       "  2.6967794777143119,\n",
       "  2.5595379159002021,\n",
       "  2.5559112293885486,\n",
       "  2.852999791060344,\n",
       "  2.5398719900905498,\n",
       "  2.58400831600227,\n",
       "  2.430919387552998,\n",
       "  2.574871865829619,\n",
       "  2.4714996130159586,\n",
       "  2.6267084933743616,\n",
       "  2.5974098809874886,\n",
       "  2.5472847258690559,\n",
       "  2.5408012748944877,\n",
       "  2.8205005626867314,\n",
       "  2.5828961759510607,\n",
       "  2.4894641460758624,\n",
       "  2.5300249345231762,\n",
       "  2.4674638899246064,\n",
       "  2.5465810180890678,\n",
       "  2.6714831342791565,\n",
       "  2.658510708572841,\n",
       "  2.6824707276750317,\n",
       "  2.6306854002546558,\n",
       "  2.8334557467167922,\n",
       "  2.9603713384949333,\n",
       "  2.6061553671808526,\n",
       "  2.6987794885540954,\n",
       "  2.5788800315101548,\n",
       "  2.6363369403499188,\n",
       "  2.7326219388754063,\n",
       "  2.6965654864169584,\n",
       "  2.6446435852806167,\n",
       "  2.6582182799235428,\n",
       "  2.6512184331912807,\n",
       "  2.6114706473775429,\n",
       "  2.7114454496024858,\n",
       "  2.7122909999129794,\n",
       "  2.6790977515796626,\n",
       "  2.6774871372940519,\n",
       "  2.647457000052575,\n",
       "  2.6484453371255703,\n",
       "  2.7608147139596468,\n",
       "  2.6201083683731534,\n",
       "  2.8319082826671034,\n",
       "  2.7504083614538213,\n",
       "  2.6394558897112854,\n",
       "  2.7980063410088567],\n",
       " [4.9976643760605617,\n",
       "  3.8084041104458346,\n",
       "  3.2647510755180131,\n",
       "  2.7634834629474301,\n",
       "  3.1323321125294901,\n",
       "  2.7420459501814136,\n",
       "  2.5968394798807579,\n",
       "  3.0137932182538627,\n",
       "  2.6669106530671072,\n",
       "  2.5680476462486945,\n",
       "  2.8695031251057541,\n",
       "  2.6201424929175046,\n",
       "  2.5924047054630694,\n",
       "  2.6821773925630175,\n",
       "  2.7796616459837056,\n",
       "  2.4853744034719938,\n",
       "  2.6115665058098219,\n",
       "  2.5572245097396396,\n",
       "  2.5568213793310788,\n",
       "  2.6725064645899406,\n",
       "  2.6408691122980401,\n",
       "  2.5114235311451525,\n",
       "  2.7130061045731648,\n",
       "  2.5438382838032032,\n",
       "  2.4911373865486373,\n",
       "  2.4256239220647529,\n",
       "  2.4873624933828222,\n",
       "  2.7824871044347783,\n",
       "  2.4481676498262011,\n",
       "  2.5865516851444057,\n",
       "  2.6551180310768658,\n",
       "  2.3901348019590474,\n",
       "  2.3676355003130318,\n",
       "  2.6114891543246732,\n",
       "  2.6382117932385736,\n",
       "  2.5285542270924783,\n",
       "  2.4899894789894028,\n",
       "  2.5920623647104395,\n",
       "  2.4249434140649173,\n",
       "  2.4510666545074766,\n",
       "  2.5846849479297602,\n",
       "  2.4098515463347483,\n",
       "  2.5492141695305852,\n",
       "  2.5110741700276291,\n",
       "  2.5228838873381663,\n",
       "  2.6440524677238844,\n",
       "  2.5624988716427644,\n",
       "  2.5136736501561532,\n",
       "  2.5137014861154086,\n",
       "  2.50778070770868,\n",
       "  2.369614596414094,\n",
       "  2.5455911277544381,\n",
       "  2.5862204580023738,\n",
       "  2.6147905387500727,\n",
       "  2.3739190998643931,\n",
       "  2.5092434080520478,\n",
       "  2.4152179661363657,\n",
       "  2.7157031097034419,\n",
       "  2.4709228052951322,\n",
       "  2.4742360256686071,\n",
       "  2.6760778757605221,\n",
       "  2.874565056054899,\n",
       "  2.30919349783718,\n",
       "  2.4229061579940341,\n",
       "  2.3744421288518622,\n",
       "  2.3963709727372273,\n",
       "  2.4261825249926878,\n",
       "  2.4030037587231927,\n",
       "  2.5816979006965561,\n",
       "  2.914867325584487,\n",
       "  2.4546380515145785,\n",
       "  2.37745738265538,\n",
       "  2.6062009263746808,\n",
       "  2.499274475739734,\n",
       "  2.4869668389310933,\n",
       "  2.638175326998871,\n",
       "  2.3680396410498288,\n",
       "  2.3951282076316303,\n",
       "  2.5157673476946236,\n",
       "  2.631528353927159,\n",
       "  2.3550327178275232,\n",
       "  2.4958160702544863,\n",
       "  2.4370930926634533,\n",
       "  2.4819316509926672,\n",
       "  2.4424011589276908,\n",
       "  2.4377615522630145,\n",
       "  2.880247172742787,\n",
       "  2.4333388498514004,\n",
       "  2.5081222930757128,\n",
       "  2.3510295660188882,\n",
       "  2.4673750471360614,\n",
       "  2.4041210212329829,\n",
       "  2.4975062219223174,\n",
       "  2.4306512634352884,\n",
       "  2.4521823071017126,\n",
       "  2.7351249562631739,\n",
       "  2.5175443403791675,\n",
       "  2.561797519721607,\n",
       "  2.570579448548874,\n",
       "  2.4591419389932461]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.2044642868608531,\n",
       " 3.3413376690137504,\n",
       " 3.0802180554607128,\n",
       " 2.7537483106745353,\n",
       " 2.9850800344259429,\n",
       " 2.6262477789774978,\n",
       " 2.5146540674832787,\n",
       " 2.6106776235127214,\n",
       " 2.507787041144796,\n",
       " 2.4787756694425456,\n",
       " 2.585597023515418,\n",
       " 2.5258169286321888,\n",
       " 2.5152736447825292,\n",
       " 2.4779716352425001,\n",
       " 2.5363712794709912,\n",
       " 2.4110965469095964,\n",
       " 2.4512662663318143,\n",
       " 2.4736000405679834,\n",
       " 2.3829104463652806,\n",
       " 2.3961918649106924,\n",
       " 2.4924046414913517,\n",
       " 2.3266107422290458,\n",
       " 2.4180197125614278,\n",
       " 2.4214332044714748,\n",
       " 2.2994860540522204,\n",
       " 2.3258951760754729,\n",
       " 2.4268021984855728,\n",
       " 2.5189601171134726,\n",
       " 2.3023252392759419,\n",
       " 2.3576867875486318,\n",
       " 2.3892791896763415,\n",
       " 2.2742678056849113,\n",
       " 2.4657421631388146,\n",
       " 2.3097065156049066,\n",
       " 2.4301378939411427,\n",
       " 2.332085394623256,\n",
       " 2.3295890777417929,\n",
       " 2.5146936449674095,\n",
       " 2.5771559960771313,\n",
       " 2.3028995849118372,\n",
       " 2.4211161443502598,\n",
       " 2.3703993676912667,\n",
       " 2.3749309152659803,\n",
       " 2.3344050197318049,\n",
       " 2.4770292987917912,\n",
       " 2.4071857126632539,\n",
       " 2.3721224246638837,\n",
       " 2.3808560678274326,\n",
       " 2.4452998177839977,\n",
       " 2.3737977117595106,\n",
       " 2.3115876901267778,\n",
       " 2.5048633530588433,\n",
       " 2.3647876541213235,\n",
       " 2.5094690299270179,\n",
       " 2.4196356334308584,\n",
       " 2.5066381834521154,\n",
       " 2.4072696336425174,\n",
       " 2.4933263264080088,\n",
       " 2.395990573533691,\n",
       " 2.3385002341600929,\n",
       " 2.4708931823768241,\n",
       " 2.5195912824998987,\n",
       " 2.266243529791879,\n",
       " 2.4582689658249954,\n",
       " 2.291616155369447,\n",
       " 2.3684360060361351,\n",
       " 2.4435918189511443,\n",
       " 2.3749705505843206,\n",
       " 2.3575480273454494,\n",
       " 2.4830486373145981,\n",
       " 2.4500357254897014,\n",
       " 2.5219856819303912,\n",
       " 2.6227233551516393,\n",
       " 2.4149107213067538,\n",
       " 2.3747137779056438,\n",
       " 2.4978417276155831,\n",
       " 2.530089335866494,\n",
       " 2.5021672201628733,\n",
       " 2.3975877986095919,\n",
       " 2.5127796619245322,\n",
       " 2.391283915774657,\n",
       " 2.6490052265696007,\n",
       " 2.4616624105094682,\n",
       " 2.5247117204241234,\n",
       " 2.4480323791503906,\n",
       " 2.4378672885422659,\n",
       " 2.6230562665674944,\n",
       " 2.3763935955444184,\n",
       " 2.402168348284051,\n",
       " 2.4979109528041121,\n",
       " 2.7046371297080918,\n",
       " 2.5528170307083884,\n",
       " 2.4672292647975507,\n",
       " 2.5969643946921472,\n",
       " 2.639757958969267,\n",
       " 2.6219173244910663,\n",
       " 2.4781054116711756,\n",
       " 2.548812664381348,\n",
       " 2.4940916854556248,\n",
       " 2.6002610178277044]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_all_scores=[np.mean([x[i] for x in all_scores]) for i in range(num_epochs)]\n",
    "avg_all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125b22278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,len(avg_all_scores)+1),avg_all_scores)\n",
    "plt.ylabel(\"MAE score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look for best parameters- no pf epochs in this case- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train final model with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0934012172245744,\n",
       " 2.4567395814574593,\n",
       " 2.7914296660092797,\n",
       " 2.5629287946342241]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4761248148313841"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)\n",
    "#avera 2.4K difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-20c05c4cff7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
